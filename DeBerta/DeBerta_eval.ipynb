{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faca4aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 21:20:14.291165: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-03 21:20:15.176105: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Any, Dict, List, Optional\n",
    "from matplotlib.axes import Axes\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification, TrainingArguments, Trainer\n",
    "colors = sns.color_palette(\"pastel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f717a7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e6ca44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There exist 14 duplicated rows.\n",
      "After removing duplicates, #samples drops from 57477 to 57470.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30aa21b3cd846ebbc2725226bf0526b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4597 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6d497af90e40c88f99192d2dbb9f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11494 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data/train.csv\")\n",
    "data.drop(\"id\", axis=1, inplace=True)\n",
    "no_rows_before = len(data)\n",
    "number_of_duplicates = data.duplicated(keep=False).sum()\n",
    "print(f\"There exist {number_of_duplicates} duplicated rows.\")\n",
    "data = data.drop_duplicates(keep=\"first\", ignore_index=True)\n",
    "no_rows_after = len(data)\n",
    "print(f\"After removing duplicates, #samples drops from {no_rows_before} to {no_rows_after}.\")\n",
    "labels = np.zeros(len(data), dtype=np.int32)\n",
    "labels[data['winner_model_a'] == 1] = 0\n",
    "labels[data['winner_model_b'] == 1] = 1\n",
    "labels[data['winner_tie'] == 1] = 2\n",
    "data[\"labels\"] = labels\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return sentences\n",
    "\n",
    "data['prompt'] = data['prompt'].apply(process)\n",
    "data['response_a'] = data['response_a'].apply(process)\n",
    "data['response_b'] = data['response_b'].apply(process)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.replace('\\n\\n', ' [NLNL] ')\n",
    "    text = text.replace('\\n', ' [NL] ')\n",
    "    return text\n",
    "\n",
    "def format_conversation(row):\n",
    "    conversations = []\n",
    "    num_turns = min(len(row['prompt']), len(row['response_a']), len(row['response_b']))\n",
    "    \n",
    "    for i in range(num_turns):\n",
    "        prompt = f\"<PROMPT> {row['prompt'][i]}\"\n",
    "        response_a = f\"<RESPONSE> [R_STRAT] {preprocess_text(row['response_a'][i])} [R_END]\"\n",
    "        response_b = f\"[R_STRAT] {preprocess_text(row['response_b'][i])} [R_END]\"\n",
    "        conversations.append(f\"{prompt} {response_a} {response_b}\")\n",
    "        \n",
    "    return ' [NLNL] '.join(conversations)\n",
    "\n",
    "data['text'] = data.apply(format_conversation, axis=1)\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(data)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = dataset['train'].select(range(int(len(dataset['train']) * 0.1)))\n",
    "val_dataset = dataset['test']\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained('fine-tuned-deberta-v3')\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained('fine-tuned-deberta-v3')\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", max_length=1024, truncation=True)\n",
    "\n",
    "# Tokenize the training and validation datasets\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "def prepare_dataset(dataset):\n",
    "    dataset = dataset.remove_columns([\"model_a\", \"model_b\", \"prompt\",\t\"response_a\", \"response_b\", \"winner_model_a\",\t\"winner_model_b\", \"winner_tie\"])\n",
    "    dataset.set_format(\"torch\")\n",
    "    return dataset\n",
    "\n",
    "train_dataset = prepare_dataset(train_dataset)\n",
    "val_dataset = prepare_dataset(val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d5a2984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds = eval_preds.predictions.argmax(-1)\n",
    "    labels = eval_preds.label_ids\n",
    "    probs = torch.from_numpy(eval_preds.predictions).float().softmax(-1).numpy()\n",
    "\n",
    "    loss = log_loss(y_true=labels, y_pred=probs)\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds)\n",
    "    return {\"acc\": acc, \"log_loss\": loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f58446bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82ab66d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1437' max='1437' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1437/1437 18:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.089062213897705, 'eval_model_preparation_time': 0.0033, 'eval_acc': 0.3668000696015312, 'eval_log_loss': 1.0890621697136182, 'eval_runtime': 1086.9653, 'eval_samples_per_second': 10.574, 'eval_steps_per_second': 1.322}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, classification_report\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402575cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
